{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f0c89f4",
   "metadata": {},
   "source": [
    "### Introduction :\n",
    "\n",
    "Ce notebook vise à developper le suivi d'un developpement ML avec l'outil MLFLOW pour une application de \"credit_scoring\". Détecter les demandeurs de crédit présentant une forte probabilité d'être défaillant.  \n",
    "Nous allons au cours de ce notebok developper un pipeline ML avec un model de base : regression logistique.\n",
    "Nous aurons assurerons : \n",
    "1. le prétraitement des données.\n",
    "2. Modélisation, teste les modèles  et le suivi du modèle et ses artéfacts sur mlflow\n",
    "3. indice du rendu métier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c2436e",
   "metadata": {},
   "source": [
    "\n",
    " ### Méthode \n",
    "1. Préprocessing\n",
    "2. Dev ML  avec la table application (train et test) : on teste tous les modèles choisis avec les données application. \n",
    "3. dev coût et seuil probabliste de promotion \n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 25,
=======
   "execution_count": 1,
>>>>>>> dev
   "id": "efdab044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% import les bibliothèques\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc # Pour la gestion de la mémoire\n",
    "import os ,re\n",
    "import sklearn as skl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score,f1_score,accuracy_score,precision_score,recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV,cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import mlflow\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ff0d658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#%% importer les tables \n",
    "len(os.listdir(\"./data\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744c9636",
   "metadata": {},
   "source": [
    "Importation des tables applications -- train & test ---  \n",
    "Ce sont les tables principales par lesquelles nous allons débuter notre developpement ainsi :  \n",
    "1. Sélection  de features\n",
    "Nous allons selectionner un nombre réduit de variables grâce la propriété de \"variable importance\" de lightgbm\n",
    "2. Construction de variable \n",
    "Nous enrichirons nos données avec des features composées ou celles des tables supplémentaires dans d'autres notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a9d2f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structure prête : 119 variables conservées.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(48744, 119)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# table application \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Chargement\n",
    "train = pd.read_csv('./data/application_train.csv')\n",
    "test = pd.read_csv('./data/application_test.csv')\n",
    "\n",
    "# Anomalie classique : 365243 jours d'emploi (~1000 ans)\n",
    "# On remplace par NaN pour que l'imputer s'en occupe proprement\n",
    "train.replace({'DAYS_EMPLOYED':365243}, np.nan, inplace=True)\n",
    "test.replace({'DAYS_EMPLOYED':365243}, np.nan, inplace=True)\n",
    "\n",
    "# Sauvegarde des IDs et de la Target\n",
    "train_labels = train['TARGET']\n",
    "train_ids = train['SK_ID_CURR']\n",
    "test_ids = test['SK_ID_CURR']\n",
    "\n",
    "# Alignement des colonnes (One-Hot Encoding)\n",
    "train.drop(columns=train.columns[train.columns.str.contains('_ID_',regex=False)], inplace=True)\n",
    "test.drop(columns=test.columns[test.columns.str.contains('_ID_',regex=False)], inplace=True)  \n",
    "#train = pd.get_dummies(train.drop(columns=['TARGET']))\n",
    "#test = pd.get_dummies(test)\n",
    "\n",
    "# On s'assure que les deux tableaux ont les mêmes colonnes\n",
    "train, test = train.align(test, join='inner', axis=1)\n",
    "\n",
    "print(f\"Structure prête : {train.shape[1]} variables conservées.\")\n",
    "train.shape\n",
    "test.shape\n",
    "### Inspection des données \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bd56a5",
   "metadata": {},
   "source": [
    "\n",
    "Vu le grand nombre de features on va se servir de lightgbm pour rechercher l'importance des variables. D'un autre côté lightgbm peut gérer des données contenant des variables catégorielles non-encodées.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a77fd6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#--- Fonction d'analyse de l'importance des variables ---\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_feature_importance(X, y,n_features=10):\n",
    "    \"\"\"\n",
    "    Entraînement d'un modèle rapide (LightGBM est idéal pour ça) On utilise class_weight='balanced' pour gérer le déséquilibre\n",
    "    @Args:\n",
    "        X: DataFrame des features\n",
    "        y: Series de la target\n",
    "    @Returns:\n",
    "        importance_df: DataFrame avec l'importance des features normalisée \n",
    "    \"\"\"\n",
    "    # 1. impléméntaion du modèle\n",
    "    model = lgb.LGBMClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "    model.fit(X.select_dtypes(include=[np.number]), y)\n",
    "    \n",
    "    # 2. Récupération de l'importance\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': X.select_dtypes(include=[np.number]).columns,\n",
    "        'importance': model.feature_importances_/sum(model.feature_importances_)\n",
    "    }).sort_values(by='importance', ascending=False\n",
    "                   )\n",
    "    \n",
    "    # 3. Visualisation\n",
    "    #plt.figure(figsize=(10, 8))\n",
    "    #sns.barplot(x='importance', y='feature', data=importance_df.head(n_features), palette='magma')\n",
    "    #plt.title(f'Top {n_features} des variables les plus importantes (LightGBM)')\n",
    "    #plt.xlabel('Importance (Gain/Split)')\n",
    "    #plt.show()\n",
    "    \n",
    "    return importance_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b649fab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 24825, number of negative: 282686\n",
<<<<<<< HEAD
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066574 seconds.\n",
=======
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043505 seconds.\n",
>>>>>>> dev
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10951\n",
      "[LightGBM] [Info] Number of data points in the train set: 307511, number of used features: 99\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Plot des 20 variables les plus importantes selon un premier jet du modèle\n",
    "importance_df =plot_feature_importance(train, train_labels,n_features=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "226d0faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((307511, 10), (48744, 10))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "### dataset restreint\n",
    "# 1. extraction  des features\n",
    "features = importance_df.feature[:10].tolist()\n",
    "\n",
    "# 2. nouveaux train et test\n",
    "train_selected = train[features]\n",
    "test_selected = test[features]  \n",
    "\n",
    "train_2ag = train_selected.copy()\n",
    "test_2ag = test_selected.copy()\n",
    "\n",
    "\n",
    "\n",
    "# dimensions des datasets sélectionnés\n",
    "train_selected.shape, test_selected.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a867b3",
   "metadata": {},
   "source": [
    " \n",
    "On obtient 2 tables de 20 fetures chacune de plus 48 000 lignes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2d7a4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de variables avec plus de 90% de valeurs manquantes :  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "#### Valeurs manquantes :\n",
    " \n",
    "#recherche de features ayant plus de 90% de valeurs manquantes \n",
    "\n",
    "print(f\"Nombre de variables avec plus de 90% de valeurs manquantes :  {(train_selected.isnull().mean()>=0.9).sum()}\")\n",
    "# existence de variables catégorielles\n",
    "cat_col = train_selected.select_dtypes(include=['object']).columns.tolist()\n",
    "len(cat_col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6f1d69",
   "metadata": {},
   "source": [
    "\n",
    "Pas de feature catégorielle dans la table de données...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "815569c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb9bba30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prétraitement et sauvegarde des datasets  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "\n",
    "# 1. Pipeline de Preprocessing\n",
    "# Median est plus robuste aux outliers que Mean pour ce dataset\n",
    "preprocessor = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', MinMaxScaler(feature_range=(0, 1)))\n",
    "])\n",
    "\n",
    "# 2. Application\n",
    "train_array= preprocessor.fit_transform(train_selected)\n",
    "#X_val_final = preprocessor.transform(X_val)\n",
    "test_array = preprocessor.transform(test_selected)\n",
    "\n",
    "# 3. Reconversion en DataFrame\n",
    "train_selected= pd.DataFrame(train_array, columns=train_selected.columns)\n",
    "#train_selected['TARGET'] = train_labels.values\n",
    "test_selected = pd.DataFrame(test_array, columns=test_selected.columns)\n",
    "\n",
    "\n",
    "\n",
    "# Sauvegarde pour le Dashboard (Etape 3)\n",
    "joblib.dump(preprocessor, 'preprocessor.pkl')\n",
    "#missing values \n",
    "train_selected.isnull().mean().mean()*100\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850e7584",
   "metadata": {},
   "source": [
    "### features inspection and cleaning \n",
    "Nous allons faire une analyse de corrélation avec la variable cible et supprimer les variables corrélées à TARGET pour l'instant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "660cb820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de colonnes avec une corrélation > 0.9: 1\n",
      "Exemples de colonnes supprimées : ['AMT_GOODS_PRICE']\n",
      "Nouveau nombre de variables : 9\n"
     ]
    }
   ],
   "source": [
    "# correlation matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns       \n",
    "corr = train_selected.corr()\n",
    "#plt.figure(figsize=(12,10))\n",
    "#sns.heatmap(corr, cmap='coolwarm_r', annot_kws={'size': 8}) \n",
    "\n",
    "corr_df = pd.DataFrame(np.triu(corr, k=1), columns=corr.columns, index=corr.index)\n",
    "#supprime les variables aux corrélations élevées\n",
    "def remove_highly_correlated_features(df, threshold=0.9):\n",
    "    # On ne calcule la corrélation que sur les variables explicatives (pas la TARGET)\n",
    "    df_features = df.drop(columns=['TARGET']) if 'TARGET' in df.columns else df\n",
    "    \n",
    "    # Calcul de la matrice de corrélation\n",
    "    corr_matrix = df_features.select_dtypes(include=[np.number]).corr().abs()\n",
    "    \n",
    "    # Sélection du triangle supérieur de la matrice (pour éviter les doublons A-B et B-A)\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    \n",
    "    # Identification des colonnes à supprimer\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    \n",
    "    print(f\"Nombre de colonnes avec une corrélation > {threshold}: {len(to_drop)}\")\n",
    "    print(f\"Exemples de colonnes supprimées : {to_drop[:10]}\")\n",
    "    \n",
    "    df_reduced = df.drop(columns=to_drop)\n",
    "    print(f\"Nouveau nombre de variables : {df_reduced.shape[1]}\")\n",
    "    \n",
    "    return df_reduced\n",
    "\n",
    "\n",
    "# Utilisation avec un seuil de 0.9 (90% de corrélation)\n",
    "train_selected = remove_highly_correlated_features(train_selected, threshold=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d91700",
   "metadata": {},
   "source": [
    "### Modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02a12070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nettoie les noms des variables \n",
    "import re\n",
    "\n",
    "def clean_column_names(df):\n",
    "    # Cette regex remplace tout caractère non-alphanumérique par un underscore\n",
    "    df.columns = [re.sub(r'[^\\w\\s]', '_', col) for col in df.columns]\n",
    "    # Remplace aussi les espaces par des underscores\n",
    "    df.columns = [col.replace(' ', '_') for col in df.columns]\n",
    "    return df\n",
    "\n",
    "#dataset_final.dropna(inplace = True,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91128b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquez le nettoyage sur vos données d'entraînement\n",
    "train_selected = clean_column_names(train_selected)\n",
    "test = clean_column_names(test)\n",
    "y = train_labels\n",
    "X = train_selected\n",
    "# 4. Split Train / Validation\n",
    "X = train_selected.drop(columns=['TARGET'], errors='ignore')\n",
    "y = train_labels\n",
    "# split \n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c6947e",
   "metadata": {},
   "source": [
    "=== ML train : MLFLOW === "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efe8c97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# préparation pour l'entraînment avec CV stratifiée\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Configuration de la CV\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d245d0",
   "metadata": {},
   "source": [
    "#### Dictionnaire des modèles "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
=======
   "execution_count": 14,
>>>>>>> dev
   "id": "a23e944b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import mlflow\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Préprocesseur pour les modèles linéaires/RF/MLP\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "])\n",
    "\n",
    "benchmark_models = {\n",
    "    \"LogisticRegression\": Pipeline(steps=[\n",
    "        ('pre', numeric_transformer), \n",
    "        ('clf', LogisticRegression(class_weight='balanced', max_iter=1000))\n",
    "    ]),\n",
    "    \n",
    "    \"RandomForest\": Pipeline(steps=[\n",
    "        ('pre', numeric_transformer), \n",
    "        ('clf', RandomForestClassifier(n_estimators=200, max_depth=10, class_weight='balanced', n_jobs=-1))\n",
    "    ]),\n",
    "    \n",
    "    \"MLP_Classifier\": Pipeline(steps=[\n",
    "        ('pre', numeric_transformer), \n",
    "        ('clf', MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=500, random_state=42))\n",
    "    ]),\n",
    "    \n",
    "    \"LightGBM\": lgb.LGBMClassifier(\n",
    "        n_estimators=500, \n",
    "        is_unbalance=True, \n",
    "        n_jobs=-1, \n",
    "        verbosity=-1,        \n",
    "        importance_type='gain'\n",
    "    ),\n",
    "    \n",
    "    \"XGBoost\": xgb.XGBClassifier(\n",
    "        n_estimators=500, \n",
    "        scale_pos_weight=11, \n",
    "        n_jobs=-1,\n",
    "        verbosity=0,         \n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "# Note : SVC est très lent sur de gros datasets. Teste-le sur un échantillon d'abord.\n",
    "# \"SVC\": SVC(probability=True, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 15,
>>>>>>> dev
   "id": "8e8a2b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On insere les contraintes métier\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "def optimize_threshold(y_true, y_probs):\n",
    "    \"\"\"\n",
    "    Trouve le seuil qui minimise le coût métier : (10 * FN) + (1 * FP).\n",
    "    \n",
    "   @Args:\n",
    "         y_true : les vraies étiquettes (0 ou 1)\n",
    "        y_probs : les probabilités prédites par le modèle (pour la classe 1)\n",
    "    @returns :\n",
    "        best_treshold : probs seuille\n",
    "        min_cost : cout minimal observé suivant la prob seuille \n",
    "    \"\"\"\n",
    "    thresholds = np.linspace(0, 1, 101)  # Teste 100 seuils de 0.0 à 1.0\n",
    "    costs = []\n",
    "    \n",
    "    for thr in thresholds:\n",
    "        # On transforme la probabilité en prédiction binaire selon le seuil\n",
    "        y_pred = (y_probs >= thr).astype(int)\n",
    "        \n",
    "        # Calcul de la matrice de confusion\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        \n",
    "        # Calcul du coût métier (pondération 10 pour les faux négatifs)\n",
    "        current_cost = (10 * fn) + (1 * fp)\n",
    "        costs.append(current_cost)\n",
    "    \n",
    "    # Trouver l'index du coût minimum\n",
    "    best_index = np.argmin(costs)\n",
    "    best_threshold = thresholds[best_index]\n",
    "    min_cost = costs[best_index]\n",
    "    \n",
    "    return best_threshold, min_cost\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b87d010",
   "metadata": {},
   "source": [
    "#### EXECUTION ML ET Log Manuel workflow "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 16,
>>>>>>> dev
   "id": "363bf4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_benchmark(X, y, experiment_name=\"Credit_Scoring_Benchmark\"):\n",
    "    \"\"\" \n",
    "    @Docs: réalise le benchmark des mmodèles pré-séléctionés\n",
    "\n",
    "    @Args : \n",
    "        X : df\n",
    "        y : cible\n",
    "        experiment°name : str nom de l'Xp\n",
    "    @Returns:\n",
    "         modele promu\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    for name, model in benchmark_models.items():\n",
    "        # Utilisation de nested=True si tu lances tout dans un seul gros run, \n",
    "        # mais ici on crée un run par modèle pour une meilleure comparaison\n",
    "        with mlflow.start_run(run_name=f\"Benchmark_{name}\"):\n",
    "            print(f\"Évaluation en cours : {name}...\")\n",
    "            \n",
    "            # Calcul des probabilités par Cross-Validation (CV=5)\n",
    "            # method='predict_proba' pour obtenir les probas de la classe 1\n",
    "            y_probs = cross_val_predict(model, X, y, cv=skf, method='predict_proba', n_jobs=-1)[:, 1]\n",
    "            \n",
    "            # Calcul des métriques\n",
    "            auc_cv = roc_auc_score(y, y_probs)\n",
    "            best_thr, business_score = optimize_threshold(y, y_probs)\n",
    "\n",
    "            cv_results = cross_validate(model, X, y, cv=skf, scoring='roc_auc', n_jobs=-1)\n",
    "            auc_mean = cv_results['test_score'].mean()\n",
    "            auc_std = cv_results['test_score'].std()\n",
    "\n",
    "            mlflow.log_metric(\"auc_mean\", auc_mean)\n",
    "            mlflow.log_metric(\"auc_std\", auc_std)\n",
    "            \n",
    "            # Logs manuels\n",
    "            mlflow.log_param(\"model_name\", name)\n",
    "            mlflow.log_metric(\"auc_cv\", auc_cv)\n",
    "            mlflow.log_metric(\"business_score_cost\", business_score)\n",
    "            mlflow.log_metric(\"optimal_threshold\", best_thr)\n",
    "            \n",
    "            # Tag pour identifier la phase\n",
    "            mlflow.set_tag(\"pipeline_step\", \"model_selection\")\n",
    "            \n",
    "            print(f\"   - {name} terminé | AUC: {auc_cv:.4f} | Coût: {business_score:.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 27,
=======
   "execution_count": 17,
>>>>>>> dev
   "id": "d40c278a",
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
=======
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/04 21:32:23 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.schemas\n",
      "2026/02/04 21:32:23 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.tables\n",
      "2026/02/04 21:32:23 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.types\n",
      "2026/02/04 21:32:23 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.constraints\n",
      "2026/02/04 21:32:23 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.defaults\n",
      "2026/02/04 21:32:23 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.comments\n",
      "2026/02/04 21:32:23 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2026/02/04 21:32:23 INFO mlflow.store.db.utils: Updating database tables\n",
      "2026/02/04 21:32:23 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/02/04 21:32:23 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2026/02/04 21:32:23 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/02/04 21:32:23 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2026/02/04 21:32:23 INFO mlflow.tracking.fluent: Experiment with name 'Credit_Scoring_Benchmark' does not exist. Creating a new experiment.\n"
     ]
    },
    {
>>>>>>> dev
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Évaluation en cours : LogisticRegression...\n",
      "   - LogisticRegression terminé | AUC: 0.7227 | Coût: 142150\n",
      "Évaluation en cours : RandomForest...\n",
<<<<<<< HEAD
      "   - RandomForest terminé | AUC: 0.7300 | Coût: 139549\n",
=======
      "   - RandomForest terminé | AUC: 0.7303 | Coût: 139236\n",
>>>>>>> dev
      "Évaluation en cours : MLP_Classifier...\n",
      "   - MLP_Classifier terminé | AUC: 0.7326 | Coût: 138382\n",
      "Évaluation en cours : LightGBM...\n",
      "   - LightGBM terminé | AUC: 0.7324 | Coût: 138419\n",
      "Évaluation en cours : XGBoost...\n",
      "   - XGBoost terminé | AUC: 0.6999 | Coût: 148474\n"
     ]
    }
   ],
   "source": [
    "# Lancement\n",
    "run_full_benchmark(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 41,
=======
   "execution_count": 18,
>>>>>>> dev
   "id": "881bdb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_best_model_from_benchmark(experiment_name=\"Credit_Scoring_Benchmark\"):\n",
    "    # 1. Récupérer l'ID de l'expérience\n",
    "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "    \n",
    "    # 2. Chercher tous les runs de cette expérience\n",
    "    # On récupère les métriques et les paramètres sous forme de DataFrame\n",
    "    runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "    \n",
    "    # 3. Trouver le run avec le coût métier le plus bas (min_cost)\n",
    "    # Note : assure-toi que le nom de la métrique correspond à celui utilisé dans log_metric\n",
    "    best_run = runs.loc[runs['metrics.business_score_cost'].idxmin()]\n",
    "    \n",
    "    print(\"-\" * 30)\n",
    "    print(f\"LE CHAMPION : {best_run['params.model_name']}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"AUC (CV): {best_run['metrics.auc_cv']:.4f}\")\n",
    "    print(f\"Coût Métier: {best_run['metrics.business_score_cost']:.0f}\")\n",
    "    print(f\"Seuil Optimal: {best_run['metrics.optimal_threshold']:.3f}\")\n",
    "    print(\"-\" * 30)\n",
    "    mlflow.sklearn.log_model(sk_model=benchmark_models[best_run['params.model_name']], name=best_run['params.model_name'],registered_model_name=best_run['params.model_name']) \n",
    "    return best_run['params.model_name']\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 42,
=======
   "execution_count": 19,
>>>>>>> dev
   "id": "60b31e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_features.pkl']"
      ]
     },
<<<<<<< HEAD
     "execution_count": 42,
=======
     "execution_count": 19,
>>>>>>> dev
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sauvergarde des features \n",
    "# À la fin du Notebook 2\n",
    "import joblib\n",
    "joblib.dump(X_train.columns.tolist(), 'selected_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 43,
=======
   "execution_count": 20,
>>>>>>> dev
   "id": "95ae0445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "LE CHAMPION : MLP_Classifier\n",
      "------------------------------\n",
      "AUC (CV): 0.7326\n",
      "Coût Métier: 138382\n",
      "Seuil Optimal: 0.090\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "2026/02/04 12:06:41 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Registered model 'MLP_Classifier' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'MLP_Classifier'.\n"
=======
      "2026/02/04 21:35:56 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2026/02/04 21:35:56 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2026/02/04 21:35:56 INFO mlflow.store.db.utils: Updating database tables\n",
      "2026/02/04 21:35:56 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/02/04 21:35:56 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "Successfully registered model 'MLP_Classifier'.\n",
      "Created version '1' of model 'MLP_Classifier'.\n"
>>>>>>> dev
     ]
    }
   ],
   "source": [
    "# Utilisation\n",
    "winner = get_best_model_from_benchmark()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet6 (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
